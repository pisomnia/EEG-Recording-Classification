{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPool2D,Reshape,Activation,BatchNormalization,Dropout,Permute\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 25, 1000)\n",
      "Test data shape: (443, 25, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({771: 543, 772: 530, 769: 529, 770: 513})\n",
      "Counter({6.0: 238, 0.0: 237, 1.0: 236, 2.0: 236, 5.0: 236, 4.0: 235, 3.0: 234, 7.0: 232, 8.0: 231})\n",
      "Counter({770: 127, 769: 111, 772: 109, 771: 96})\n",
      "Counter({0.0: 50, 1.0: 50, 2.0: 50, 3.0: 50, 6.0: 50, 7.0: 50, 5.0: 49, 4.0: 47, 8.0: 47})\n"
     ]
    }
   ],
   "source": [
    "c1 = Counter(y_train_valid)\n",
    "d1 = Counter(person_train_valid[:,0])\n",
    "print(c1)\n",
    "print(d1)\n",
    "c2 = Counter(y_test)\n",
    "d2 = Counter(person_test[:,0])\n",
    "print(c2)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject_0</th>\n",
       "      <th>Subject_1</th>\n",
       "      <th>Subject_2</th>\n",
       "      <th>Subject_3</th>\n",
       "      <th>Subject_4</th>\n",
       "      <th>Subject_5</th>\n",
       "      <th>Subject_6</th>\n",
       "      <th>Subject_7</th>\n",
       "      <th>Subject_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foot</th>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tongue</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Subject_0  Subject_1  Subject_2  Subject_3  Subject_4  Subject_5  \\\n",
       "left           60         60         56         66         55         57   \n",
       "right          59         57         60         54         60         55   \n",
       "foot           58         62         63         56         59         62   \n",
       "tongue         60         57         57         58         61         62   \n",
       "\n",
       "        Subject_6  Subject_7  Subject_8  \n",
       "left           59         60         56  \n",
       "right          54         56         58  \n",
       "foot           64         60         59  \n",
       "tongue         61         56         58  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subject=np.array([0,1,2,3,4,5,6,7,8])\n",
    "Class =np.array([769,770,771,772])\n",
    "data=np.zeros([4,9])\n",
    "for i in range(4):\n",
    "    for j in range(9):\n",
    "        loc=np.argwhere(person_train_valid==Subject[j])[:,0]\n",
    "        data[i,j]=sum(y_train_valid[loc]==Class[i])\n",
    "\n",
    "idx_name=['left','right','foot','tongue']\n",
    "column_name=['Subject_0', 'Subject_1','Subject_2','Subject_3','Subject_4','Subject_5','Subject_6','Subject_7','Subject_8']\n",
    "df = pd.DataFrame(data=data,index=idx_name, columns=column_name)\n",
    "df.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Splitting data by subject \n",
    "person_train_valid = person_train_valid.astype(int)\n",
    "person_test = person_test.astype(int)\n",
    "\n",
    "ids = range(0, 9) # IDs 0-8 inclusive\n",
    "\n",
    "train_valid_subject_idx = defaultdict(list) # key: id 0-8, value: list of indices of training data for that id \n",
    "test_subject_idx = defaultdict(list)\n",
    "\n",
    "num_trials, num_channels, num_bins = X_train_valid.shape\n",
    "num_test = X_test.shape[0]\n",
    "\n",
    "for i in range(num_trials):\n",
    "    train_valid_subject_idx[person_train_valid[i][0]].append(i)\n",
    "    \n",
    "for i in range(num_test):\n",
    "    test_subject_idx[person_test[i][0]].append(i)\n",
    "# Sanity check to see if partitioning by subject ID worked\n",
    "\n",
    "print(len(train_valid_subject_idx[0]))\n",
    "print(len(test_subject_idx[0]))   \n",
    "# change the label in one-hot encoding\n",
    "y_train_valid-=769\n",
    "y_test-=769\n",
    "y_train_valid_onehot = to_categorical(y_train_valid)\n",
    "y_test_onehot= to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 25, 1000, 1)\n",
      "Test data shape: (443, 25, 1000, 1)\n",
      "Original Training data shape: (1692, 25, 1000, 1)\n",
      "Original Validation data shape: (423, 25, 1000, 1)\n",
      "Original Testing data shape: (443, 25, 1000, 1)\n",
      "3Second Training data shape: (1692, 25, 750, 1)\n",
      "3Second Validation data shape: (423, 25, 750, 1)\n",
      "3Second Testing data shape: (443, 25, 750, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the training data and Validation data\n",
    "# Remove the 1st decond which is the cue period\n",
    "EEG_22=False\n",
    "is_3s=True\n",
    "n_sub = 2\n",
    "split_size=0.2\n",
    "#True:{1,2,3,5,10,15} False:{1,2,4,5,8,10,20}\n",
    "if EEG_22==True:\n",
    "    EEG_train_valid = X_train_valid[:,:22,:].reshape(-1,22,1000,1)\n",
    "    EEG_test  = X_test[:,:22,:].reshape(-1,22,1000,1)\n",
    "else:\n",
    "    EEG_train_valid = X_train_valid[:,:25,:].reshape(-1,25,1000,1)\n",
    "    EEG_test  = X_test[:,:25,:].reshape(-1,25,1000,1)\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(EEG_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(EEG_test.shape))\n",
    "\n",
    "n_train=int(2115*(1-split_size))\n",
    "n_valid=int(2115*split_size)\n",
    "n_test=443\n",
    "\n",
    "EEG_train, EEG_valid, y_train, y_valid = train_test_split(\n",
    "    EEG_train_valid, y_train_valid_onehot, test_size=split_size, shuffle=True)\n",
    "\n",
    "print ('Original Training data shape: {}'.format(EEG_train.shape))\n",
    "print ('Original Validation data shape: {}'.format(EEG_valid.shape))\n",
    "print ('Original Testing data shape: {}'.format(EEG_test.shape))\n",
    "EEG_3s_train=EEG_train[:,:,250:1000,:]\n",
    "EEG_3s_valid=EEG_valid[:,:,250:1000,:]\n",
    "EEG_3s_test=EEG_test[:,:,250:1000,:]\n",
    "print ('3Second Training data shape: {}'.format(EEG_3s_train.shape))\n",
    "print ('3Second Validation data shape: {}'.format(EEG_3s_valid.shape))\n",
    "print ('3Second Testing data shape: {}'.format(EEG_3s_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down sample the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use the 3-seconds data:\n",
      "New Training data shape: (3384, 25, 375, 1)\n",
      "New Validation data shape: (846, 25, 375, 1)\n",
      "New Testing data shape: (886, 25, 375, 1)\n"
     ]
    }
   ],
   "source": [
    "if is_3s==True:\n",
    "    print(\"use the 3-seconds data:\")\n",
    "    new_train=np.zeros([n_train*n_sub,EEG_train.shape[1],750//n_sub,1],dtype='float64')\n",
    "    new_valid=np.zeros([n_valid*n_sub,EEG_train.shape[1],750//n_sub,1],dtype='float64')\n",
    "    new_test=np.zeros([n_test*n_sub,EEG_train.shape[1],750//n_sub,1],dtype='float64')    \n",
    "else:\n",
    "    print(\"use the 4-seconds data:\")\n",
    "    new_train=np.zeros([n_train*n_sub,EEG_train.shape[1],1000//n_sub,1],dtype='float64')\n",
    "    new_valid=np.zeros([n_valid*n_sub,EEG_train.shape[1],1000//n_sub,1],dtype='float64')\n",
    "    new_test=np.zeros([n_test*n_sub,EEG_train.shape[1],1000//n_sub,1],dtype='float64')\n",
    "yy_train= np.zeros([new_train.shape[0],4],dtype='float64')\n",
    "yy_valid= np.zeros([new_valid.shape[0],4],dtype='float64')\n",
    "yy_test_onehot= np.zeros([new_test.shape[0],4],dtype='float64')\n",
    "for i in range(n_sub)  :\n",
    "    if is_3s==True:\n",
    "        new_train[i*n_train:(i+1)*n_train]=EEG_3s_train[:,:,i:750:n_sub,:]\n",
    "        new_valid[i*n_valid:(i+1)*n_valid]=EEG_3s_valid[:,:,i:750:n_sub,:]\n",
    "        new_test[i*n_test:(i+1)*n_test]=EEG_3s_test[:,:,i:750:n_sub,:]\n",
    "    else:\n",
    "        new_train[i*n_train:(i+1)*n_train]=EEG_train[:,:,i:1000:n_sub,:]\n",
    "        new_valid[i*n_valid:(i+1)*n_valid]=EEG_valid[:,:,i:1000:n_sub,:]\n",
    "        new_test[i*n_test:(i+1)*n_test]=EEG_test[:,:,i:1000:n_sub,:]\n",
    "    yy_train[i*n_train:(i+1)*n_train]= y_train\n",
    "    yy_valid[i*n_valid:(i+1)*n_valid]=y_valid\n",
    "    yy_test_onehot[i*n_test:(i+1)*n_test]=y_test_onehot\n",
    "print ('New Training data shape: {}'.format(new_train.shape))\n",
    "print ('New Validation data shape: {}'.format(new_valid.shape))\n",
    "print ('New Testing data shape: {}'.format(new_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Deep ConvNet Architecture (with down sample Data)\n",
    "Input Dimension: 25x375x1\n",
    "0. `Projected FC Block`\n",
    "<br>Fully connected layer\n",
    "<br>  $\\longrightarrow$ 30x375x1\n",
    "1. `Conv-Pool Block`\n",
    "<br>Convolutional layer with 60 1x15 kernels, with stride 1,3, valid padding\n",
    "<br>  $\\longrightarrow$ 30x121x60\n",
    "<br>ELU \n",
    "<br>Max Pooling Stride 1x2 with same padding \n",
    "<br>  $\\longrightarrow$ 30x61x60\n",
    "2. `Conv-Pool Block`\n",
    "<br>Convolutional layer with 60 1x4 kernels, with stride 1,2,valid padding\n",
    "<br>  $\\longrightarrow$ 30x29x60\n",
    "<br>ELU\n",
    "<br>Max Pooling Stride 1x2 with same padding \n",
    "<br>  $\\longrightarrow$ 30x15x60\n",
    "3. `Conv-Pool Block`\n",
    "<br>Convolutional layer with 60 30x1 kernels, with stride 1,1,valid padding\n",
    "<br>  $\\longrightarrow$ 1x15x60\n",
    "<br>ELU\n",
    "<br>Convolutional layer with 90 1x3 kernels, with stride 1,1,same padding\n",
    "<br>  $\\longrightarrow$ 1x15x90\n",
    "<br>ELU\n",
    "<br>Max Pooling Stride 1x2, with same padding \n",
    "<br>  $\\longrightarrow$ 1x8x90\n",
    "\n",
    "4. `Conv-Pool Block`\n",
    "<br>Convolutional layer with 120 1x3 kernels, with stride 1,1,same padding\n",
    "<br>  $\\longrightarrow$ 1x8x120\n",
    "<br>ELU\n",
    "<br>Max Pooling Stride 1x2, same padding\n",
    "<br>  $\\longrightarrow$ 1x4x120\n",
    "5. `FC Layer`\n",
    "<br> Flatten\n",
    "<br>  $\\longrightarrow$ 480\n",
    "<br> Dense Layer \n",
    "<br>  $\\longrightarrow$ 95\n",
    "6. `Classification Layer`\n",
    "<br> Dense Layer \n",
    "<br>  $\\longrightarrow$ 4\n",
    "<br> Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Flatten(input_shape=(22,375,1)))\n",
    "#model.add(Dense(11250,kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(Reshape((30, 375,1)))\n",
    "#model.add(Activation('elu'))\n",
    "VarianceScaling=keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None)\n",
    "model.add(Permute(( 3,2,1),input_shape=(25,375,1)))\n",
    "#model.add(Dense(40,kernel_initializer=VarianceScaling,bias_initializer='zeros',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(30,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Permute((3,2,1)))\n",
    "#model.add(Activation('elu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(60, kernel_size=(1,15), strides=(1,3),padding='valid',kernel_regularizer=regularizers.l2(0.01),input_shape=(22,375,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPool2D(pool_size=(1,2),strides=(1,2),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(60, kernel_size=(1,4), strides=(1,2),padding='valid',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPool2D(pool_size=(1,2),strides=(1,2),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(60, kernel_size=(30,1), strides=(1,1),padding='valid',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(90, kernel_size=(1,3), strides=(1,1),padding='same',kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPool2D(pool_size=(1,2),strides=(1,2),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(120, kernel_size=(1,3), strides=(1,1),padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPool2D(pool_size=(1,2),strides=(1,2),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(95,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam= optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "rmsprop= optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "#model.compile(optimizer=sgd,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3384 samples, validate on 846 samples\n",
      "Epoch 1/500\n",
      "3384/3384 [==============================] - 30s 9ms/step - loss: 7.3610 - acc: 0.2485 - val_loss: 6.1348 - val_acc: 0.2801\n",
      "Epoch 2/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 6.6357 - acc: 0.2680 - val_loss: 6.0212 - val_acc: 0.3357\n",
      "Epoch 3/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 6.3792 - acc: 0.2352 - val_loss: 5.9126 - val_acc: 0.3262\n",
      "Epoch 4/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 6.1226 - acc: 0.2651 - val_loss: 5.8255 - val_acc: 0.2872\n",
      "Epoch 5/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 5.9554 - acc: 0.2733 - val_loss: 5.7212 - val_acc: 0.3050\n",
      "Epoch 6/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 5.7966 - acc: 0.2745 - val_loss: 5.6133 - val_acc: 0.3097\n",
      "Epoch 7/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 5.6817 - acc: 0.2701 - val_loss: 5.5124 - val_acc: 0.3097\n",
      "Epoch 8/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 5.5670 - acc: 0.2559 - val_loss: 5.4204 - val_acc: 0.3121\n",
      "Epoch 9/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 5.4442 - acc: 0.2887 - val_loss: 5.3296 - val_acc: 0.3274\n",
      "Epoch 10/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 5.3267 - acc: 0.2810 - val_loss: 5.2369 - val_acc: 0.3180\n",
      "Epoch 11/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 5.2267 - acc: 0.2955 - val_loss: 5.1458 - val_acc: 0.3168\n",
      "Epoch 12/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 5.1457 - acc: 0.2757 - val_loss: 5.0641 - val_acc: 0.3132\n",
      "Epoch 13/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 5.0614 - acc: 0.2671 - val_loss: 4.9791 - val_acc: 0.3215\n",
      "Epoch 14/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 4.9607 - acc: 0.2769 - val_loss: 4.8940 - val_acc: 0.3109\n",
      "Epoch 15/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 4.8765 - acc: 0.2757 - val_loss: 4.8103 - val_acc: 0.3310\n",
      "Epoch 16/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 4.7930 - acc: 0.2798 - val_loss: 4.7316 - val_acc: 0.3239\n",
      "Epoch 17/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 4.7051 - acc: 0.3126 - val_loss: 4.6518 - val_acc: 0.3144\n",
      "Epoch 18/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 4.6279 - acc: 0.3153 - val_loss: 4.5740 - val_acc: 0.3345\n",
      "Epoch 19/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 4.5538 - acc: 0.2955 - val_loss: 4.4941 - val_acc: 0.3570\n",
      "Epoch 20/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 4.4765 - acc: 0.3106 - val_loss: 4.4197 - val_acc: 0.3452\n",
      "Epoch 21/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 4.4042 - acc: 0.3180 - val_loss: 4.3470 - val_acc: 0.3546\n",
      "Epoch 22/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 4.3308 - acc: 0.3197 - val_loss: 4.2737 - val_acc: 0.3522\n",
      "Epoch 23/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 4.2588 - acc: 0.3221 - val_loss: 4.2009 - val_acc: 0.3440\n",
      "Epoch 24/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 4.1870 - acc: 0.3274 - val_loss: 4.1314 - val_acc: 0.3487\n",
      "Epoch 25/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 4.1236 - acc: 0.3304 - val_loss: 4.0629 - val_acc: 0.3605\n",
      "Epoch 26/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 4.0534 - acc: 0.3416 - val_loss: 3.9934 - val_acc: 0.3570\n",
      "Epoch 27/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 3.9859 - acc: 0.3401 - val_loss: 3.9263 - val_acc: 0.3747\n",
      "Epoch 28/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 3.9180 - acc: 0.3493 - val_loss: 3.8584 - val_acc: 0.3853\n",
      "Epoch 29/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 3.8515 - acc: 0.3472 - val_loss: 3.7899 - val_acc: 0.3830\n",
      "Epoch 30/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 3.7939 - acc: 0.3587 - val_loss: 3.7247 - val_acc: 0.3806\n",
      "Epoch 31/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 3.7254 - acc: 0.3771 - val_loss: 3.6595 - val_acc: 0.3960\n",
      "Epoch 32/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 3.6631 - acc: 0.3815 - val_loss: 3.5964 - val_acc: 0.4090\n",
      "Epoch 33/500\n",
      "3384/3384 [==============================] - 1s 421us/step - loss: 3.5982 - acc: 0.3862 - val_loss: 3.5376 - val_acc: 0.3913\n",
      "Epoch 34/500\n",
      "3384/3384 [==============================] - 1s 425us/step - loss: 3.5372 - acc: 0.3948 - val_loss: 3.4745 - val_acc: 0.4220\n",
      "Epoch 35/500\n",
      "3384/3384 [==============================] - 1s 422us/step - loss: 3.4736 - acc: 0.4122 - val_loss: 3.4120 - val_acc: 0.4314\n",
      "Epoch 36/500\n",
      "3384/3384 [==============================] - 1s 421us/step - loss: 3.4211 - acc: 0.4119 - val_loss: 3.3598 - val_acc: 0.4184\n",
      "Epoch 37/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 3.3582 - acc: 0.4300 - val_loss: 3.2969 - val_acc: 0.4385\n",
      "Epoch 38/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 3.3103 - acc: 0.4320 - val_loss: 3.2456 - val_acc: 0.4433\n",
      "Epoch 39/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 3.2520 - acc: 0.4356 - val_loss: 3.1862 - val_acc: 0.4716\n",
      "Epoch 40/500\n",
      "3384/3384 [==============================] - 1s 422us/step - loss: 3.1958 - acc: 0.4699 - val_loss: 3.1292 - val_acc: 0.4669\n",
      "Epoch 41/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 3.1384 - acc: 0.4545 - val_loss: 3.0672 - val_acc: 0.4787\n",
      "Epoch 42/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 3.0777 - acc: 0.4808 - val_loss: 3.0071 - val_acc: 0.4941\n",
      "Epoch 43/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 3.0191 - acc: 0.4879 - val_loss: 2.9469 - val_acc: 0.5024\n",
      "Epoch 44/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 2.9667 - acc: 0.5139 - val_loss: 2.8964 - val_acc: 0.5012\n",
      "Epoch 45/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.9199 - acc: 0.5100 - val_loss: 2.8540 - val_acc: 0.5012\n",
      "Epoch 46/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 2.8558 - acc: 0.5281 - val_loss: 2.7994 - val_acc: 0.5177\n",
      "Epoch 47/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.8083 - acc: 0.5346 - val_loss: 2.7590 - val_acc: 0.5118\n",
      "Epoch 48/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.7644 - acc: 0.5381 - val_loss: 2.7112 - val_acc: 0.5296\n",
      "Epoch 49/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 2.7146 - acc: 0.5355 - val_loss: 2.6707 - val_acc: 0.5272\n",
      "Epoch 50/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.6755 - acc: 0.5417 - val_loss: 2.6089 - val_acc: 0.5449\n",
      "Epoch 51/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.6232 - acc: 0.5461 - val_loss: 2.5842 - val_acc: 0.5532\n",
      "Epoch 52/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 2.5839 - acc: 0.5609 - val_loss: 2.5440 - val_acc: 0.5473\n",
      "Epoch 53/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 2.5309 - acc: 0.5615 - val_loss: 2.4883 - val_acc: 0.5674\n",
      "Epoch 54/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.4974 - acc: 0.5635 - val_loss: 2.4508 - val_acc: 0.5615\n",
      "Epoch 55/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.4484 - acc: 0.5600 - val_loss: 2.4004 - val_acc: 0.5804\n",
      "Epoch 56/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.4216 - acc: 0.5624 - val_loss: 2.3821 - val_acc: 0.5709\n",
      "Epoch 57/500\n",
      "3384/3384 [==============================] - 1s 424us/step - loss: 2.3800 - acc: 0.5762 - val_loss: 2.3298 - val_acc: 0.5946\n",
      "Epoch 58/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.3445 - acc: 0.5751 - val_loss: 2.3045 - val_acc: 0.5780\n",
      "Epoch 59/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 2.3057 - acc: 0.5851 - val_loss: 2.2781 - val_acc: 0.5839\n",
      "Epoch 60/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 2.2663 - acc: 0.5887 - val_loss: 2.2313 - val_acc: 0.5910\n",
      "Epoch 61/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 2.2305 - acc: 0.5966 - val_loss: 2.1948 - val_acc: 0.6040\n",
      "Epoch 62/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 2.1948 - acc: 0.6002 - val_loss: 2.1624 - val_acc: 0.6052\n",
      "Epoch 63/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 2.1568 - acc: 0.6182 - val_loss: 2.1284 - val_acc: 0.6135\n",
      "Epoch 64/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 2.1006 - acc: 0.6291 - val_loss: 2.1080 - val_acc: 0.6135\n",
      "Epoch 65/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 2.0798 - acc: 0.6126 - val_loss: 2.0605 - val_acc: 0.6170\n",
      "Epoch 66/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 2.0420 - acc: 0.6167 - val_loss: 2.0317 - val_acc: 0.6158\n",
      "Epoch 67/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 2.0227 - acc: 0.6164 - val_loss: 1.9809 - val_acc: 0.6359\n",
      "Epoch 68/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.9891 - acc: 0.6226 - val_loss: 1.9787 - val_acc: 0.6123\n",
      "Epoch 69/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.9573 - acc: 0.6315 - val_loss: 1.9344 - val_acc: 0.6312\n",
      "Epoch 70/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.9314 - acc: 0.6315 - val_loss: 1.9323 - val_acc: 0.6300\n",
      "Epoch 71/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.9053 - acc: 0.6427 - val_loss: 1.9074 - val_acc: 0.6182\n",
      "Epoch 72/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.8672 - acc: 0.6336 - val_loss: 1.8501 - val_acc: 0.6537\n",
      "Epoch 73/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.8403 - acc: 0.6439 - val_loss: 1.8596 - val_acc: 0.6300\n",
      "Epoch 74/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.8292 - acc: 0.6427 - val_loss: 1.8096 - val_acc: 0.6418\n",
      "Epoch 75/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.7948 - acc: 0.6483 - val_loss: 1.8477 - val_acc: 0.6005\n",
      "Epoch 76/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.7645 - acc: 0.6480 - val_loss: 1.7734 - val_acc: 0.6430\n",
      "Epoch 77/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.7321 - acc: 0.6681 - val_loss: 1.7510 - val_acc: 0.6300\n",
      "Epoch 78/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.7108 - acc: 0.6676 - val_loss: 1.7400 - val_acc: 0.6158\n",
      "Epoch 79/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.6854 - acc: 0.6723 - val_loss: 1.7206 - val_acc: 0.6383\n",
      "Epoch 80/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.6624 - acc: 0.6690 - val_loss: 1.7303 - val_acc: 0.6229\n",
      "Epoch 81/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.6263 - acc: 0.6749 - val_loss: 1.6658 - val_acc: 0.6513\n",
      "Epoch 82/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 1.6042 - acc: 0.6788 - val_loss: 1.7094 - val_acc: 0.6170\n",
      "Epoch 83/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.5829 - acc: 0.6868 - val_loss: 1.6365 - val_acc: 0.6525\n",
      "Epoch 84/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.5625 - acc: 0.6865 - val_loss: 1.6027 - val_acc: 0.6407\n",
      "Epoch 85/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.5434 - acc: 0.6885 - val_loss: 1.5850 - val_acc: 0.6584\n",
      "Epoch 86/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.5271 - acc: 0.6939 - val_loss: 1.5556 - val_acc: 0.6560\n",
      "Epoch 87/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.4871 - acc: 0.6974 - val_loss: 1.5566 - val_acc: 0.6525\n",
      "Epoch 88/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.4869 - acc: 0.6912 - val_loss: 1.5531 - val_acc: 0.6395\n",
      "Epoch 89/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.4483 - acc: 0.7092 - val_loss: 1.5841 - val_acc: 0.6489\n",
      "Epoch 90/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.4464 - acc: 0.6968 - val_loss: 1.5198 - val_acc: 0.6548\n",
      "Epoch 91/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.4137 - acc: 0.6947 - val_loss: 1.5789 - val_acc: 0.6359\n",
      "Epoch 92/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.3942 - acc: 0.7234 - val_loss: 1.4672 - val_acc: 0.6797\n",
      "Epoch 93/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.3924 - acc: 0.7045 - val_loss: 1.4221 - val_acc: 0.6856\n",
      "Epoch 94/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.3685 - acc: 0.7110 - val_loss: 1.4021 - val_acc: 0.6927\n",
      "Epoch 95/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.3340 - acc: 0.7302 - val_loss: 1.4130 - val_acc: 0.6726\n",
      "Epoch 96/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.3001 - acc: 0.7320 - val_loss: 1.4199 - val_acc: 0.6903\n",
      "Epoch 97/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.3069 - acc: 0.7204 - val_loss: 1.4268 - val_acc: 0.6596\n",
      "Epoch 98/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.2886 - acc: 0.7240 - val_loss: 1.3721 - val_acc: 0.6903\n",
      "Epoch 99/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.2861 - acc: 0.7264 - val_loss: 1.4313 - val_acc: 0.6631\n",
      "Epoch 100/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.2703 - acc: 0.7210 - val_loss: 1.3970 - val_acc: 0.6714\n",
      "Epoch 101/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.2609 - acc: 0.7252 - val_loss: 1.3370 - val_acc: 0.6785\n",
      "Epoch 102/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.2326 - acc: 0.7332 - val_loss: 1.4199 - val_acc: 0.6596\n",
      "Epoch 103/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.2082 - acc: 0.7411 - val_loss: 1.3543 - val_acc: 0.6596\n",
      "Epoch 104/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.2003 - acc: 0.7417 - val_loss: 1.2949 - val_acc: 0.6915\n",
      "Epoch 105/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.2055 - acc: 0.7352 - val_loss: 1.2823 - val_acc: 0.6879\n",
      "Epoch 106/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.1734 - acc: 0.7491 - val_loss: 1.3063 - val_acc: 0.7080\n",
      "Epoch 107/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.1742 - acc: 0.7358 - val_loss: 1.3057 - val_acc: 0.6785\n",
      "Epoch 108/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.1305 - acc: 0.7577 - val_loss: 1.3123 - val_acc: 0.6643\n",
      "Epoch 109/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.1403 - acc: 0.7417 - val_loss: 1.2305 - val_acc: 0.6962\n",
      "Epoch 110/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.1003 - acc: 0.7636 - val_loss: 1.2744 - val_acc: 0.6903\n",
      "Epoch 111/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.0939 - acc: 0.7530 - val_loss: 1.3349 - val_acc: 0.6702\n",
      "Epoch 112/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.0850 - acc: 0.7547 - val_loss: 1.2725 - val_acc: 0.7092\n",
      "Epoch 113/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.0781 - acc: 0.7488 - val_loss: 1.1846 - val_acc: 0.7281\n",
      "Epoch 114/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.0912 - acc: 0.7527 - val_loss: 1.2306 - val_acc: 0.6856\n",
      "Epoch 115/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.0614 - acc: 0.7538 - val_loss: 1.1992 - val_acc: 0.6986\n",
      "Epoch 116/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.0348 - acc: 0.7716 - val_loss: 1.1937 - val_acc: 0.7104\n",
      "Epoch 117/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 1.0468 - acc: 0.7592 - val_loss: 1.2237 - val_acc: 0.6844\n",
      "Epoch 118/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 1.0448 - acc: 0.7574 - val_loss: 1.1947 - val_acc: 0.7069\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.0075 - acc: 0.7683 - val_loss: 1.2964 - val_acc: 0.6690\n",
      "Epoch 120/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.0325 - acc: 0.7645 - val_loss: 1.2600 - val_acc: 0.6584\n",
      "Epoch 121/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.9980 - acc: 0.7704 - val_loss: 1.3290 - val_acc: 0.6324\n",
      "Epoch 122/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 1.0002 - acc: 0.7710 - val_loss: 1.2430 - val_acc: 0.6525\n",
      "Epoch 123/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.9785 - acc: 0.7772 - val_loss: 1.2858 - val_acc: 0.6548\n",
      "Epoch 124/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.9674 - acc: 0.7754 - val_loss: 1.2419 - val_acc: 0.6785\n",
      "Epoch 125/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.9446 - acc: 0.7807 - val_loss: 1.1669 - val_acc: 0.6879\n",
      "Epoch 126/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.9700 - acc: 0.7686 - val_loss: 1.2469 - val_acc: 0.6655\n",
      "Epoch 127/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.9357 - acc: 0.7775 - val_loss: 1.1821 - val_acc: 0.7057\n",
      "Epoch 128/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.9388 - acc: 0.7775 - val_loss: 1.1492 - val_acc: 0.6844\n",
      "Epoch 129/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.9415 - acc: 0.7713 - val_loss: 1.1524 - val_acc: 0.6962\n",
      "Epoch 130/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.9324 - acc: 0.7769 - val_loss: 1.1476 - val_acc: 0.7092\n",
      "Epoch 131/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.9212 - acc: 0.7822 - val_loss: 1.2144 - val_acc: 0.6738\n",
      "Epoch 132/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.9306 - acc: 0.7772 - val_loss: 1.1223 - val_acc: 0.6868\n",
      "Epoch 133/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.8917 - acc: 0.7943 - val_loss: 1.1892 - val_acc: 0.6678\n",
      "Epoch 134/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.8768 - acc: 0.7967 - val_loss: 1.1317 - val_acc: 0.6738\n",
      "Epoch 135/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.8771 - acc: 0.7926 - val_loss: 1.1897 - val_acc: 0.6643\n",
      "Epoch 136/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.8648 - acc: 0.7931 - val_loss: 1.1193 - val_acc: 0.7057\n",
      "Epoch 137/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.8567 - acc: 0.8011 - val_loss: 1.1604 - val_acc: 0.6950\n",
      "Epoch 138/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.8621 - acc: 0.7931 - val_loss: 1.3879 - val_acc: 0.6265\n",
      "Epoch 139/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.8653 - acc: 0.7946 - val_loss: 1.1185 - val_acc: 0.7116\n",
      "Epoch 140/500\n",
      "3384/3384 [==============================] - 1s 421us/step - loss: 0.8349 - acc: 0.8002 - val_loss: 1.1191 - val_acc: 0.7092\n",
      "Epoch 141/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.8453 - acc: 0.7991 - val_loss: 1.1338 - val_acc: 0.6667\n",
      "Epoch 142/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.8472 - acc: 0.7914 - val_loss: 1.0890 - val_acc: 0.6962\n",
      "Epoch 143/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.8406 - acc: 0.7955 - val_loss: 1.0698 - val_acc: 0.6915\n",
      "Epoch 144/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.8294 - acc: 0.7955 - val_loss: 1.1390 - val_acc: 0.6714\n",
      "Epoch 145/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.8369 - acc: 0.7976 - val_loss: 1.1097 - val_acc: 0.6974\n",
      "Epoch 146/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.8079 - acc: 0.8073 - val_loss: 1.1704 - val_acc: 0.7069\n",
      "Epoch 147/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.7993 - acc: 0.8067 - val_loss: 1.0941 - val_acc: 0.6749\n",
      "Epoch 148/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.8148 - acc: 0.7988 - val_loss: 1.1017 - val_acc: 0.6903\n",
      "Epoch 149/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7999 - acc: 0.7961 - val_loss: 1.1147 - val_acc: 0.6809\n",
      "Epoch 150/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.7983 - acc: 0.7970 - val_loss: 1.0903 - val_acc: 0.7104\n",
      "Epoch 151/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7937 - acc: 0.8067 - val_loss: 1.1066 - val_acc: 0.6986\n",
      "Epoch 152/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.7639 - acc: 0.8180 - val_loss: 1.0782 - val_acc: 0.6832\n",
      "Epoch 153/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7926 - acc: 0.8061 - val_loss: 1.0949 - val_acc: 0.6809\n",
      "Epoch 154/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.7477 - acc: 0.8171 - val_loss: 1.1247 - val_acc: 0.6702\n",
      "Epoch 155/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.7798 - acc: 0.8121 - val_loss: 1.2481 - val_acc: 0.6489\n",
      "Epoch 156/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.7559 - acc: 0.8085 - val_loss: 1.1321 - val_acc: 0.6832\n",
      "Epoch 157/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7621 - acc: 0.8103 - val_loss: 1.1179 - val_acc: 0.6761\n",
      "Epoch 158/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7707 - acc: 0.8032 - val_loss: 1.0323 - val_acc: 0.6986\n",
      "Epoch 159/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.7581 - acc: 0.8171 - val_loss: 1.0665 - val_acc: 0.6950\n",
      "Epoch 160/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.7431 - acc: 0.8144 - val_loss: 1.1278 - val_acc: 0.6738\n",
      "Epoch 161/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7458 - acc: 0.8162 - val_loss: 1.0530 - val_acc: 0.7116\n",
      "Epoch 162/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7474 - acc: 0.8230 - val_loss: 1.0374 - val_acc: 0.6998\n",
      "Epoch 163/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.7548 - acc: 0.8129 - val_loss: 1.1467 - val_acc: 0.6631\n",
      "Epoch 164/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7248 - acc: 0.8227 - val_loss: 1.2120 - val_acc: 0.6726\n",
      "Epoch 165/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.7565 - acc: 0.8005 - val_loss: 1.1248 - val_acc: 0.6832\n",
      "Epoch 166/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7431 - acc: 0.8171 - val_loss: 1.0312 - val_acc: 0.7045\n",
      "Epoch 167/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7479 - acc: 0.8132 - val_loss: 1.0670 - val_acc: 0.6820\n",
      "Epoch 168/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7128 - acc: 0.8283 - val_loss: 1.0289 - val_acc: 0.7080\n",
      "Epoch 169/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.7342 - acc: 0.8165 - val_loss: 1.1318 - val_acc: 0.6513\n",
      "Epoch 170/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7245 - acc: 0.8186 - val_loss: 1.0660 - val_acc: 0.6962\n",
      "Epoch 171/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7207 - acc: 0.8197 - val_loss: 1.0897 - val_acc: 0.6844\n",
      "Epoch 172/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7015 - acc: 0.8274 - val_loss: 1.1277 - val_acc: 0.6856\n",
      "Epoch 173/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.7089 - acc: 0.8298 - val_loss: 1.1285 - val_acc: 0.6548\n",
      "Epoch 174/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6955 - acc: 0.8286 - val_loss: 1.2403 - val_acc: 0.6501\n",
      "Epoch 175/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7102 - acc: 0.8206 - val_loss: 1.1741 - val_acc: 0.6655\n",
      "Epoch 176/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.7098 - acc: 0.8227 - val_loss: 1.1045 - val_acc: 0.7222\n",
      "Epoch 177/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6842 - acc: 0.8274 - val_loss: 1.1061 - val_acc: 0.7021\n",
      "Epoch 178/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6842 - acc: 0.8336 - val_loss: 1.0352 - val_acc: 0.7009\n",
      "Epoch 179/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.6911 - acc: 0.8265 - val_loss: 1.0733 - val_acc: 0.6903\n",
      "Epoch 180/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6785 - acc: 0.8351 - val_loss: 1.0010 - val_acc: 0.7187\n",
      "Epoch 181/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6847 - acc: 0.8289 - val_loss: 1.1722 - val_acc: 0.6738\n",
      "Epoch 182/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6796 - acc: 0.8339 - val_loss: 1.2716 - val_acc: 0.6418\n",
      "Epoch 183/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.7213 - acc: 0.8197 - val_loss: 1.1048 - val_acc: 0.6738\n",
      "Epoch 184/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.7043 - acc: 0.8274 - val_loss: 1.2026 - val_acc: 0.6525\n",
      "Epoch 185/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.7217 - acc: 0.8162 - val_loss: 1.0832 - val_acc: 0.6891\n",
      "Epoch 186/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6724 - acc: 0.8366 - val_loss: 1.1439 - val_acc: 0.6773\n",
      "Epoch 187/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6696 - acc: 0.8401 - val_loss: 1.1321 - val_acc: 0.6998\n",
      "Epoch 188/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6842 - acc: 0.8268 - val_loss: 1.0234 - val_acc: 0.7092\n",
      "Epoch 189/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6797 - acc: 0.8389 - val_loss: 1.0266 - val_acc: 0.7270\n",
      "Epoch 190/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6554 - acc: 0.8395 - val_loss: 1.0580 - val_acc: 0.6939\n",
      "Epoch 191/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6701 - acc: 0.8345 - val_loss: 1.0917 - val_acc: 0.6915\n",
      "Epoch 192/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6694 - acc: 0.8457 - val_loss: 1.0247 - val_acc: 0.7163\n",
      "Epoch 193/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6703 - acc: 0.8366 - val_loss: 1.1183 - val_acc: 0.7009\n",
      "Epoch 194/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6493 - acc: 0.8419 - val_loss: 1.0335 - val_acc: 0.7199\n",
      "Epoch 195/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6611 - acc: 0.8345 - val_loss: 1.1113 - val_acc: 0.6974\n",
      "Epoch 196/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6538 - acc: 0.8401 - val_loss: 1.1127 - val_acc: 0.7045\n",
      "Epoch 197/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6622 - acc: 0.8339 - val_loss: 1.1390 - val_acc: 0.6856\n",
      "Epoch 198/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6883 - acc: 0.8286 - val_loss: 1.0649 - val_acc: 0.6998\n",
      "Epoch 199/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6416 - acc: 0.8460 - val_loss: 1.1226 - val_acc: 0.6915\n",
      "Epoch 200/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.6364 - acc: 0.8407 - val_loss: 1.3172 - val_acc: 0.6489\n",
      "Epoch 201/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6888 - acc: 0.8292 - val_loss: 1.0927 - val_acc: 0.7009\n",
      "Epoch 202/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6568 - acc: 0.8410 - val_loss: 1.1128 - val_acc: 0.6856\n",
      "Epoch 203/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6689 - acc: 0.8339 - val_loss: 1.0295 - val_acc: 0.7092\n",
      "Epoch 204/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.6489 - acc: 0.8460 - val_loss: 1.0429 - val_acc: 0.7222\n",
      "Epoch 205/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6637 - acc: 0.8398 - val_loss: 1.1655 - val_acc: 0.6962\n",
      "Epoch 206/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6708 - acc: 0.8327 - val_loss: 1.0558 - val_acc: 0.6998\n",
      "Epoch 207/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6401 - acc: 0.8499 - val_loss: 1.2091 - val_acc: 0.6738\n",
      "Epoch 208/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6550 - acc: 0.8478 - val_loss: 1.2075 - val_acc: 0.6631\n",
      "Epoch 209/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6405 - acc: 0.8469 - val_loss: 1.0943 - val_acc: 0.7116\n",
      "Epoch 210/500\n",
      "3384/3384 [==============================] - 1s 426us/step - loss: 0.6495 - acc: 0.8392 - val_loss: 1.2298 - val_acc: 0.6631\n",
      "Epoch 211/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6283 - acc: 0.8534 - val_loss: 1.0726 - val_acc: 0.6891\n",
      "Epoch 212/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6383 - acc: 0.8484 - val_loss: 1.0711 - val_acc: 0.7175\n",
      "Epoch 213/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6675 - acc: 0.8283 - val_loss: 1.1948 - val_acc: 0.6773\n",
      "Epoch 214/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6305 - acc: 0.8499 - val_loss: 1.0668 - val_acc: 0.7069\n",
      "Epoch 215/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6270 - acc: 0.8514 - val_loss: 1.2382 - val_acc: 0.6655\n",
      "Epoch 216/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6323 - acc: 0.8466 - val_loss: 1.1613 - val_acc: 0.6832\n",
      "Epoch 217/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.6553 - acc: 0.8398 - val_loss: 1.1315 - val_acc: 0.6820\n",
      "Epoch 218/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.6226 - acc: 0.8508 - val_loss: 1.2195 - val_acc: 0.6702\n",
      "Epoch 219/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6325 - acc: 0.8499 - val_loss: 1.0404 - val_acc: 0.7199\n",
      "Epoch 220/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6285 - acc: 0.8508 - val_loss: 1.3527 - val_acc: 0.6454\n",
      "Epoch 221/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6521 - acc: 0.8387 - val_loss: 1.1058 - val_acc: 0.6974\n",
      "Epoch 222/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6283 - acc: 0.8520 - val_loss: 1.1055 - val_acc: 0.6844\n",
      "Epoch 223/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6524 - acc: 0.8475 - val_loss: 1.0483 - val_acc: 0.7021\n",
      "Epoch 224/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6261 - acc: 0.8493 - val_loss: 1.0716 - val_acc: 0.7033\n",
      "Epoch 225/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6215 - acc: 0.8558 - val_loss: 1.2796 - val_acc: 0.6714\n",
      "Epoch 226/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6192 - acc: 0.8499 - val_loss: 1.1432 - val_acc: 0.6726\n",
      "Epoch 227/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6480 - acc: 0.8443 - val_loss: 1.1093 - val_acc: 0.6879\n",
      "Epoch 228/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6212 - acc: 0.8502 - val_loss: 1.0853 - val_acc: 0.6891\n",
      "Epoch 229/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.6338 - acc: 0.8517 - val_loss: 1.1104 - val_acc: 0.6986\n",
      "Epoch 230/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6034 - acc: 0.8620 - val_loss: 1.1907 - val_acc: 0.6738\n",
      "Epoch 231/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6340 - acc: 0.8463 - val_loss: 1.1971 - val_acc: 0.6856\n",
      "Epoch 232/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6259 - acc: 0.8466 - val_loss: 1.3637 - val_acc: 0.6608\n",
      "Epoch 233/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6328 - acc: 0.8534 - val_loss: 1.1594 - val_acc: 0.6690\n",
      "Epoch 234/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6383 - acc: 0.8490 - val_loss: 1.1349 - val_acc: 0.6939\n",
      "Epoch 235/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6249 - acc: 0.8546 - val_loss: 1.1500 - val_acc: 0.6844\n",
      "Epoch 236/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6198 - acc: 0.8520 - val_loss: 1.2035 - val_acc: 0.6939\n",
      "Epoch 237/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6255 - acc: 0.8511 - val_loss: 1.1069 - val_acc: 0.6903\n",
      "Epoch 238/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6147 - acc: 0.8579 - val_loss: 1.3036 - val_acc: 0.6525\n",
      "Epoch 239/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6307 - acc: 0.8466 - val_loss: 1.0888 - val_acc: 0.7104\n",
      "Epoch 240/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6091 - acc: 0.8582 - val_loss: 1.1863 - val_acc: 0.6915\n",
      "Epoch 241/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6226 - acc: 0.8490 - val_loss: 1.1961 - val_acc: 0.6773\n",
      "Epoch 242/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6089 - acc: 0.8558 - val_loss: 1.0853 - val_acc: 0.7187\n",
      "Epoch 243/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6163 - acc: 0.8520 - val_loss: 1.2765 - val_acc: 0.6738\n",
      "Epoch 244/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6156 - acc: 0.8549 - val_loss: 1.1209 - val_acc: 0.6927\n",
      "Epoch 245/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6318 - acc: 0.8508 - val_loss: 1.0953 - val_acc: 0.7151\n",
      "Epoch 246/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6240 - acc: 0.8587 - val_loss: 1.3354 - val_acc: 0.6359\n",
      "Epoch 247/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6385 - acc: 0.8434 - val_loss: 1.1280 - val_acc: 0.6939\n",
      "Epoch 248/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6189 - acc: 0.8499 - val_loss: 1.2841 - val_acc: 0.6643\n",
      "Epoch 249/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6110 - acc: 0.8611 - val_loss: 1.1438 - val_acc: 0.6832\n",
      "Epoch 250/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6112 - acc: 0.8564 - val_loss: 1.1371 - val_acc: 0.6903\n",
      "Epoch 251/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5907 - acc: 0.8629 - val_loss: 1.2092 - val_acc: 0.6832\n",
      "Epoch 252/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6061 - acc: 0.8623 - val_loss: 1.1405 - val_acc: 0.6962\n",
      "Epoch 253/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6004 - acc: 0.8602 - val_loss: 1.1556 - val_acc: 0.6998\n",
      "Epoch 254/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6342 - acc: 0.8478 - val_loss: 1.0957 - val_acc: 0.6974\n",
      "Epoch 255/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.6053 - acc: 0.8602 - val_loss: 1.1846 - val_acc: 0.6915\n",
      "Epoch 256/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6177 - acc: 0.8570 - val_loss: 1.1116 - val_acc: 0.7092\n",
      "Epoch 257/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5984 - acc: 0.8664 - val_loss: 1.0817 - val_acc: 0.7139\n",
      "Epoch 258/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5936 - acc: 0.8673 - val_loss: 1.1536 - val_acc: 0.6986\n",
      "Epoch 259/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6118 - acc: 0.8555 - val_loss: 1.0843 - val_acc: 0.7021\n",
      "Epoch 260/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6070 - acc: 0.8644 - val_loss: 1.1760 - val_acc: 0.6903\n",
      "Epoch 261/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5981 - acc: 0.8664 - val_loss: 1.0738 - val_acc: 0.7210\n",
      "Epoch 262/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6084 - acc: 0.8525 - val_loss: 1.2550 - val_acc: 0.6773\n",
      "Epoch 263/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6127 - acc: 0.8570 - val_loss: 1.1297 - val_acc: 0.6962\n",
      "Epoch 264/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6391 - acc: 0.8490 - val_loss: 1.0862 - val_acc: 0.7057\n",
      "Epoch 265/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6044 - acc: 0.8605 - val_loss: 1.0858 - val_acc: 0.6950\n",
      "Epoch 266/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6134 - acc: 0.8596 - val_loss: 0.9930 - val_acc: 0.7388\n",
      "Epoch 267/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6134 - acc: 0.8652 - val_loss: 1.3861 - val_acc: 0.6170\n",
      "Epoch 268/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5954 - acc: 0.8664 - val_loss: 1.1766 - val_acc: 0.6797\n",
      "Epoch 269/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6172 - acc: 0.8650 - val_loss: 1.2499 - val_acc: 0.6690\n",
      "Epoch 270/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6201 - acc: 0.8590 - val_loss: 1.0486 - val_acc: 0.7270\n",
      "Epoch 271/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6133 - acc: 0.8579 - val_loss: 1.0785 - val_acc: 0.7199\n",
      "Epoch 272/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6254 - acc: 0.8558 - val_loss: 1.1073 - val_acc: 0.6939\n",
      "Epoch 273/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5977 - acc: 0.8655 - val_loss: 1.0233 - val_acc: 0.7329\n",
      "Epoch 274/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6040 - acc: 0.8641 - val_loss: 1.0387 - val_acc: 0.7376\n",
      "Epoch 275/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5877 - acc: 0.8682 - val_loss: 1.1157 - val_acc: 0.6974\n",
      "Epoch 276/500\n",
      "3384/3384 [==============================] - 1s 421us/step - loss: 0.6028 - acc: 0.8605 - val_loss: 1.1928 - val_acc: 0.6879\n",
      "Epoch 277/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5966 - acc: 0.8652 - val_loss: 1.1176 - val_acc: 0.7199\n",
      "Epoch 278/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5804 - acc: 0.8762 - val_loss: 1.0648 - val_acc: 0.7128\n",
      "Epoch 279/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6188 - acc: 0.8596 - val_loss: 1.0785 - val_acc: 0.7045\n",
      "Epoch 280/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5936 - acc: 0.8726 - val_loss: 1.1056 - val_acc: 0.7092\n",
      "Epoch 281/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6205 - acc: 0.8602 - val_loss: 1.2116 - val_acc: 0.6856\n",
      "Epoch 282/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6022 - acc: 0.8655 - val_loss: 1.3234 - val_acc: 0.6749\n",
      "Epoch 283/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6045 - acc: 0.8655 - val_loss: 1.1227 - val_acc: 0.7069\n",
      "Epoch 284/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6006 - acc: 0.8611 - val_loss: 1.1198 - val_acc: 0.7175\n",
      "Epoch 285/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5811 - acc: 0.8712 - val_loss: 1.0811 - val_acc: 0.7234\n",
      "Epoch 286/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5790 - acc: 0.8738 - val_loss: 1.2063 - val_acc: 0.6678\n",
      "Epoch 287/500\n",
      "3384/3384 [==============================] - 1s 421us/step - loss: 0.6007 - acc: 0.8661 - val_loss: 1.1389 - val_acc: 0.6879\n",
      "Epoch 288/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.6022 - acc: 0.8655 - val_loss: 1.0794 - val_acc: 0.7092\n",
      "Epoch 289/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5889 - acc: 0.8717 - val_loss: 1.1173 - val_acc: 0.7080\n",
      "Epoch 290/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5953 - acc: 0.8673 - val_loss: 1.0926 - val_acc: 0.6998\n",
      "Epoch 291/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6077 - acc: 0.8638 - val_loss: 1.0352 - val_acc: 0.7128\n",
      "Epoch 292/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6122 - acc: 0.8587 - val_loss: 1.1617 - val_acc: 0.6974\n",
      "Epoch 293/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6000 - acc: 0.8650 - val_loss: 1.1355 - val_acc: 0.7080\n",
      "Epoch 294/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5871 - acc: 0.8759 - val_loss: 1.1280 - val_acc: 0.7163\n",
      "Epoch 295/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5925 - acc: 0.8723 - val_loss: 1.0723 - val_acc: 0.7293\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5897 - acc: 0.8712 - val_loss: 1.0838 - val_acc: 0.7116\n",
      "Epoch 297/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5784 - acc: 0.8735 - val_loss: 1.1717 - val_acc: 0.6809\n",
      "Epoch 298/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5889 - acc: 0.8697 - val_loss: 1.1104 - val_acc: 0.7021\n",
      "Epoch 299/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6046 - acc: 0.8703 - val_loss: 1.0654 - val_acc: 0.6962\n",
      "Epoch 300/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6343 - acc: 0.8576 - val_loss: 1.0632 - val_acc: 0.7080\n",
      "Epoch 301/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6071 - acc: 0.8641 - val_loss: 1.3158 - val_acc: 0.6513\n",
      "Epoch 302/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6013 - acc: 0.8641 - val_loss: 1.0917 - val_acc: 0.7092\n",
      "Epoch 303/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6002 - acc: 0.8753 - val_loss: 1.1124 - val_acc: 0.6998\n",
      "Epoch 304/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5830 - acc: 0.8720 - val_loss: 1.0725 - val_acc: 0.7317\n",
      "Epoch 305/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5700 - acc: 0.8830 - val_loss: 1.1576 - val_acc: 0.7270\n",
      "Epoch 306/500\n",
      "3384/3384 [==============================] - 1s 424us/step - loss: 0.5950 - acc: 0.8703 - val_loss: 1.1113 - val_acc: 0.7057\n",
      "Epoch 307/500\n",
      "3384/3384 [==============================] - 1s 422us/step - loss: 0.5938 - acc: 0.8717 - val_loss: 1.0617 - val_acc: 0.7139\n",
      "Epoch 308/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5786 - acc: 0.8729 - val_loss: 1.1854 - val_acc: 0.6797\n",
      "Epoch 309/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5986 - acc: 0.8688 - val_loss: 1.1691 - val_acc: 0.6820\n",
      "Epoch 310/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5903 - acc: 0.8644 - val_loss: 1.0387 - val_acc: 0.7388\n",
      "Epoch 311/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5739 - acc: 0.8794 - val_loss: 1.1259 - val_acc: 0.7293\n",
      "Epoch 312/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5997 - acc: 0.8655 - val_loss: 1.1993 - val_acc: 0.6879\n",
      "Epoch 313/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6006 - acc: 0.8682 - val_loss: 1.3012 - val_acc: 0.6608\n",
      "Epoch 314/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5890 - acc: 0.8744 - val_loss: 1.1517 - val_acc: 0.6915\n",
      "Epoch 315/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5927 - acc: 0.8738 - val_loss: 1.1465 - val_acc: 0.6998\n",
      "Epoch 316/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5725 - acc: 0.8800 - val_loss: 1.1020 - val_acc: 0.7163\n",
      "Epoch 317/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5901 - acc: 0.8676 - val_loss: 1.1186 - val_acc: 0.7139\n",
      "Epoch 318/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5929 - acc: 0.8685 - val_loss: 1.1237 - val_acc: 0.7199\n",
      "Epoch 319/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5737 - acc: 0.8732 - val_loss: 1.0963 - val_acc: 0.7069\n",
      "Epoch 320/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5970 - acc: 0.8753 - val_loss: 1.1552 - val_acc: 0.7139\n",
      "Epoch 321/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6001 - acc: 0.8673 - val_loss: 1.1660 - val_acc: 0.7092\n",
      "Epoch 322/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5983 - acc: 0.8667 - val_loss: 1.1438 - val_acc: 0.7234\n",
      "Epoch 323/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6070 - acc: 0.8644 - val_loss: 1.0497 - val_acc: 0.7175\n",
      "Epoch 324/500\n",
      "3384/3384 [==============================] - 1s 421us/step - loss: 0.5931 - acc: 0.8717 - val_loss: 1.0907 - val_acc: 0.7151\n",
      "Epoch 325/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5895 - acc: 0.8735 - val_loss: 1.1636 - val_acc: 0.6820\n",
      "Epoch 326/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5805 - acc: 0.8788 - val_loss: 1.0629 - val_acc: 0.7423\n",
      "Epoch 327/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5938 - acc: 0.8750 - val_loss: 1.3052 - val_acc: 0.6832\n",
      "Epoch 328/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5550 - acc: 0.8818 - val_loss: 1.0555 - val_acc: 0.7163\n",
      "Epoch 329/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5503 - acc: 0.8895 - val_loss: 1.2204 - val_acc: 0.7045\n",
      "Epoch 330/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.6125 - acc: 0.8632 - val_loss: 1.1231 - val_acc: 0.7128\n",
      "Epoch 331/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.6010 - acc: 0.8635 - val_loss: 1.1070 - val_acc: 0.7069\n",
      "Epoch 332/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5686 - acc: 0.8818 - val_loss: 1.1648 - val_acc: 0.6868\n",
      "Epoch 333/500\n",
      "3384/3384 [==============================] - 1s 421us/step - loss: 0.5927 - acc: 0.8720 - val_loss: 1.2880 - val_acc: 0.6785\n",
      "Epoch 334/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5808 - acc: 0.8738 - val_loss: 1.1478 - val_acc: 0.6844\n",
      "Epoch 335/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5902 - acc: 0.8747 - val_loss: 1.5846 - val_acc: 0.6040\n",
      "Epoch 336/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5855 - acc: 0.8756 - val_loss: 1.0334 - val_acc: 0.7234\n",
      "Epoch 337/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5872 - acc: 0.8774 - val_loss: 1.2444 - val_acc: 0.6702\n",
      "Epoch 338/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5815 - acc: 0.8771 - val_loss: 1.1989 - val_acc: 0.6962\n",
      "Epoch 339/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5753 - acc: 0.8735 - val_loss: 1.1096 - val_acc: 0.7057\n",
      "Epoch 340/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5702 - acc: 0.8815 - val_loss: 1.1369 - val_acc: 0.7175\n",
      "Epoch 341/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5653 - acc: 0.8880 - val_loss: 1.1371 - val_acc: 0.7104\n",
      "Epoch 342/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5813 - acc: 0.8717 - val_loss: 1.2111 - val_acc: 0.6879\n",
      "Epoch 343/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5728 - acc: 0.8818 - val_loss: 1.2481 - val_acc: 0.6773\n",
      "Epoch 344/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5704 - acc: 0.8797 - val_loss: 1.2644 - val_acc: 0.6773\n",
      "Epoch 345/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5992 - acc: 0.8661 - val_loss: 1.1059 - val_acc: 0.7080\n",
      "Epoch 346/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.6030 - acc: 0.8709 - val_loss: 1.1618 - val_acc: 0.7139\n",
      "Epoch 347/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5794 - acc: 0.8783 - val_loss: 1.1035 - val_acc: 0.7222\n",
      "Epoch 348/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5991 - acc: 0.8697 - val_loss: 1.0771 - val_acc: 0.7270\n",
      "Epoch 349/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5746 - acc: 0.8853 - val_loss: 1.1522 - val_acc: 0.7021\n",
      "Epoch 350/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5719 - acc: 0.8797 - val_loss: 1.1725 - val_acc: 0.7080\n",
      "Epoch 351/500\n",
      "3384/3384 [==============================] - 1s 421us/step - loss: 0.6043 - acc: 0.8726 - val_loss: 1.0807 - val_acc: 0.7210\n",
      "Epoch 352/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5974 - acc: 0.8700 - val_loss: 1.0885 - val_acc: 0.7270\n",
      "Epoch 353/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5942 - acc: 0.8706 - val_loss: 1.1647 - val_acc: 0.6844\n",
      "Epoch 354/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5869 - acc: 0.8706 - val_loss: 1.1318 - val_acc: 0.7293\n",
      "Epoch 355/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5776 - acc: 0.8836 - val_loss: 1.2443 - val_acc: 0.6844\n",
      "Epoch 356/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5663 - acc: 0.8833 - val_loss: 1.4174 - val_acc: 0.6123\n",
      "Epoch 357/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5850 - acc: 0.8750 - val_loss: 1.1503 - val_acc: 0.6844\n",
      "Epoch 358/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5898 - acc: 0.8709 - val_loss: 1.1582 - val_acc: 0.6950\n",
      "Epoch 359/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5388 - acc: 0.8945 - val_loss: 1.1209 - val_acc: 0.7210\n",
      "Epoch 360/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5722 - acc: 0.8874 - val_loss: 1.1176 - val_acc: 0.7317\n",
      "Epoch 361/500\n",
      "3384/3384 [==============================] - 1s 421us/step - loss: 0.5973 - acc: 0.8694 - val_loss: 1.1022 - val_acc: 0.7222\n",
      "Epoch 362/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5790 - acc: 0.8809 - val_loss: 1.2565 - val_acc: 0.6749\n",
      "Epoch 363/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5654 - acc: 0.8859 - val_loss: 1.1897 - val_acc: 0.6832\n",
      "Epoch 364/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5806 - acc: 0.8803 - val_loss: 1.1306 - val_acc: 0.6986\n",
      "Epoch 365/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5663 - acc: 0.8836 - val_loss: 1.1116 - val_acc: 0.7210\n",
      "Epoch 366/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5660 - acc: 0.8818 - val_loss: 1.0855 - val_acc: 0.7258\n",
      "Epoch 367/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5820 - acc: 0.8720 - val_loss: 1.2852 - val_acc: 0.6655\n",
      "Epoch 368/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5740 - acc: 0.8815 - val_loss: 1.3142 - val_acc: 0.6572\n",
      "Epoch 369/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5661 - acc: 0.8883 - val_loss: 1.1438 - val_acc: 0.7163\n",
      "Epoch 370/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5646 - acc: 0.8868 - val_loss: 1.1613 - val_acc: 0.6974\n",
      "Epoch 371/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5814 - acc: 0.8756 - val_loss: 1.1672 - val_acc: 0.6915\n",
      "Epoch 372/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5663 - acc: 0.8865 - val_loss: 1.1854 - val_acc: 0.6927\n",
      "Epoch 373/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5716 - acc: 0.8800 - val_loss: 1.2408 - val_acc: 0.6809\n",
      "Epoch 374/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5641 - acc: 0.8889 - val_loss: 1.2029 - val_acc: 0.7033\n",
      "Epoch 375/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5679 - acc: 0.8785 - val_loss: 1.0595 - val_acc: 0.7281\n",
      "Epoch 376/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5676 - acc: 0.8850 - val_loss: 1.2479 - val_acc: 0.6820\n",
      "Epoch 377/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5866 - acc: 0.8771 - val_loss: 1.3022 - val_acc: 0.6525\n",
      "Epoch 378/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5882 - acc: 0.8717 - val_loss: 1.2050 - val_acc: 0.6797\n",
      "Epoch 379/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5935 - acc: 0.8712 - val_loss: 1.2407 - val_acc: 0.6773\n",
      "Epoch 380/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5714 - acc: 0.8809 - val_loss: 1.0975 - val_acc: 0.7210\n",
      "Epoch 381/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5711 - acc: 0.8915 - val_loss: 1.0881 - val_acc: 0.7281\n",
      "Epoch 382/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5755 - acc: 0.8806 - val_loss: 1.1785 - val_acc: 0.6998\n",
      "Epoch 383/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5641 - acc: 0.8853 - val_loss: 1.1448 - val_acc: 0.7222\n",
      "Epoch 384/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.6026 - acc: 0.8741 - val_loss: 1.1735 - val_acc: 0.6903\n",
      "Epoch 385/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5504 - acc: 0.8933 - val_loss: 1.0535 - val_acc: 0.7329\n",
      "Epoch 386/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5771 - acc: 0.8821 - val_loss: 1.1920 - val_acc: 0.7009\n",
      "Epoch 387/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5496 - acc: 0.8921 - val_loss: 1.2286 - val_acc: 0.6891\n",
      "Epoch 388/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5960 - acc: 0.8709 - val_loss: 1.0818 - val_acc: 0.7352\n",
      "Epoch 389/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5737 - acc: 0.8824 - val_loss: 1.2040 - val_acc: 0.7009\n",
      "Epoch 390/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5607 - acc: 0.8824 - val_loss: 1.1678 - val_acc: 0.6998\n",
      "Epoch 391/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5898 - acc: 0.8765 - val_loss: 1.1213 - val_acc: 0.7281\n",
      "Epoch 392/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5546 - acc: 0.8874 - val_loss: 1.2384 - val_acc: 0.6749\n",
      "Epoch 393/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5776 - acc: 0.8898 - val_loss: 1.1914 - val_acc: 0.6998\n",
      "Epoch 394/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5603 - acc: 0.8886 - val_loss: 1.1511 - val_acc: 0.7234\n",
      "Epoch 395/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5638 - acc: 0.8827 - val_loss: 1.0840 - val_acc: 0.7199\n",
      "Epoch 396/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5687 - acc: 0.8907 - val_loss: 1.0982 - val_acc: 0.7080\n",
      "Epoch 397/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5662 - acc: 0.8848 - val_loss: 1.2402 - val_acc: 0.6986\n",
      "Epoch 398/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5907 - acc: 0.8744 - val_loss: 1.1071 - val_acc: 0.7128\n",
      "Epoch 399/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5441 - acc: 0.8933 - val_loss: 1.1099 - val_acc: 0.6962\n",
      "Epoch 400/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5474 - acc: 0.8892 - val_loss: 1.1225 - val_acc: 0.7151\n",
      "Epoch 401/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5762 - acc: 0.8774 - val_loss: 1.2643 - val_acc: 0.6797\n",
      "Epoch 402/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5610 - acc: 0.8871 - val_loss: 1.0807 - val_acc: 0.7270\n",
      "Epoch 403/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5683 - acc: 0.8818 - val_loss: 1.0832 - val_acc: 0.7270\n",
      "Epoch 404/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5780 - acc: 0.8809 - val_loss: 1.2941 - val_acc: 0.6749\n",
      "Epoch 405/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6002 - acc: 0.8720 - val_loss: 1.2787 - val_acc: 0.6868\n",
      "Epoch 406/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5527 - acc: 0.8942 - val_loss: 1.1730 - val_acc: 0.7116\n",
      "Epoch 407/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5714 - acc: 0.8735 - val_loss: 1.1760 - val_acc: 0.7045\n",
      "Epoch 408/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5868 - acc: 0.8818 - val_loss: 1.3115 - val_acc: 0.6927\n",
      "Epoch 409/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5757 - acc: 0.8791 - val_loss: 1.2461 - val_acc: 0.6915\n",
      "Epoch 410/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5717 - acc: 0.8818 - val_loss: 1.2148 - val_acc: 0.6915\n",
      "Epoch 411/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5784 - acc: 0.8848 - val_loss: 1.1677 - val_acc: 0.7080\n",
      "Epoch 412/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5502 - acc: 0.8963 - val_loss: 1.1199 - val_acc: 0.7187\n",
      "Epoch 413/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5677 - acc: 0.8785 - val_loss: 1.1477 - val_acc: 0.7092\n",
      "Epoch 414/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5725 - acc: 0.8836 - val_loss: 1.2913 - val_acc: 0.6608\n",
      "Epoch 415/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5852 - acc: 0.8797 - val_loss: 1.1083 - val_acc: 0.7246\n",
      "Epoch 416/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5981 - acc: 0.8777 - val_loss: 1.1807 - val_acc: 0.7045\n",
      "Epoch 417/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5793 - acc: 0.8803 - val_loss: 1.1624 - val_acc: 0.7104\n",
      "Epoch 418/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5570 - acc: 0.8933 - val_loss: 1.1851 - val_acc: 0.7080\n",
      "Epoch 419/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5757 - acc: 0.8839 - val_loss: 1.1945 - val_acc: 0.6974\n",
      "Epoch 420/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5852 - acc: 0.8780 - val_loss: 1.1650 - val_acc: 0.6879\n",
      "Epoch 421/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5675 - acc: 0.8883 - val_loss: 1.1466 - val_acc: 0.7139\n",
      "Epoch 422/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5622 - acc: 0.8874 - val_loss: 1.2335 - val_acc: 0.6950\n",
      "Epoch 423/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5579 - acc: 0.8886 - val_loss: 1.1763 - val_acc: 0.6891\n",
      "Epoch 424/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5779 - acc: 0.8800 - val_loss: 1.1091 - val_acc: 0.7258\n",
      "Epoch 425/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5538 - acc: 0.8871 - val_loss: 1.2075 - val_acc: 0.7116\n",
      "Epoch 426/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5630 - acc: 0.8904 - val_loss: 1.0865 - val_acc: 0.7234\n",
      "Epoch 427/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5702 - acc: 0.8827 - val_loss: 1.1259 - val_acc: 0.7128\n",
      "Epoch 428/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5449 - acc: 0.8927 - val_loss: 1.1578 - val_acc: 0.7057\n",
      "Epoch 429/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5415 - acc: 0.8989 - val_loss: 1.2299 - val_acc: 0.7092\n",
      "Epoch 430/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5701 - acc: 0.8892 - val_loss: 1.0902 - val_acc: 0.7222\n",
      "Epoch 431/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5777 - acc: 0.8839 - val_loss: 1.1173 - val_acc: 0.7057\n",
      "Epoch 432/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5497 - acc: 0.8913 - val_loss: 1.2383 - val_acc: 0.6797\n",
      "Epoch 433/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.6068 - acc: 0.8717 - val_loss: 1.1954 - val_acc: 0.7080\n",
      "Epoch 434/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5503 - acc: 0.8933 - val_loss: 1.1740 - val_acc: 0.7246\n",
      "Epoch 435/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5758 - acc: 0.8827 - val_loss: 1.2338 - val_acc: 0.6903\n",
      "Epoch 436/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5352 - acc: 0.9025 - val_loss: 1.2491 - val_acc: 0.6915\n",
      "Epoch 437/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5866 - acc: 0.8762 - val_loss: 1.1952 - val_acc: 0.7222\n",
      "Epoch 438/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5667 - acc: 0.8918 - val_loss: 1.1279 - val_acc: 0.7246\n",
      "Epoch 439/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5875 - acc: 0.8750 - val_loss: 1.2160 - val_acc: 0.6903\n",
      "Epoch 440/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5589 - acc: 0.8859 - val_loss: 1.2134 - val_acc: 0.6986\n",
      "Epoch 441/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5359 - acc: 0.8921 - val_loss: 1.1646 - val_acc: 0.7092\n",
      "Epoch 442/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5899 - acc: 0.8777 - val_loss: 1.1649 - val_acc: 0.7187\n",
      "Epoch 443/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5687 - acc: 0.8839 - val_loss: 1.0814 - val_acc: 0.7281\n",
      "Epoch 444/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5485 - acc: 0.8930 - val_loss: 1.2393 - val_acc: 0.6891\n",
      "Epoch 445/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5671 - acc: 0.8850 - val_loss: 1.1920 - val_acc: 0.7210\n",
      "Epoch 446/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5549 - acc: 0.8930 - val_loss: 1.1694 - val_acc: 0.6974\n",
      "Epoch 447/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5655 - acc: 0.8921 - val_loss: 1.1019 - val_acc: 0.7258\n",
      "Epoch 448/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5709 - acc: 0.8827 - val_loss: 1.1557 - val_acc: 0.6927\n",
      "Epoch 449/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5301 - acc: 0.9010 - val_loss: 1.1464 - val_acc: 0.7151\n",
      "Epoch 450/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5546 - acc: 0.8924 - val_loss: 1.1233 - val_acc: 0.7139\n",
      "Epoch 451/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5818 - acc: 0.8803 - val_loss: 1.2009 - val_acc: 0.7163\n",
      "Epoch 452/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5684 - acc: 0.8883 - val_loss: 1.1738 - val_acc: 0.7139\n",
      "Epoch 453/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5709 - acc: 0.8845 - val_loss: 1.1291 - val_acc: 0.7400\n",
      "Epoch 454/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5356 - acc: 0.9043 - val_loss: 1.1203 - val_acc: 0.7210\n",
      "Epoch 455/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5392 - acc: 0.8957 - val_loss: 1.2162 - val_acc: 0.6974\n",
      "Epoch 456/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5502 - acc: 0.8915 - val_loss: 1.1107 - val_acc: 0.7258\n",
      "Epoch 457/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5642 - acc: 0.8910 - val_loss: 1.2201 - val_acc: 0.7057\n",
      "Epoch 458/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5306 - acc: 0.8963 - val_loss: 1.2867 - val_acc: 0.6513\n",
      "Epoch 459/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5686 - acc: 0.8845 - val_loss: 1.1647 - val_acc: 0.6891\n",
      "Epoch 460/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5498 - acc: 0.8978 - val_loss: 1.2998 - val_acc: 0.6726\n",
      "Epoch 461/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5436 - acc: 0.8910 - val_loss: 1.1773 - val_acc: 0.7116\n",
      "Epoch 462/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5578 - acc: 0.8930 - val_loss: 1.3163 - val_acc: 0.6596\n",
      "Epoch 463/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5660 - acc: 0.8892 - val_loss: 1.1855 - val_acc: 0.6998\n",
      "Epoch 464/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5758 - acc: 0.8880 - val_loss: 1.2669 - val_acc: 0.6950\n",
      "Epoch 465/500\n",
      "3384/3384 [==============================] - 1s 428us/step - loss: 0.5685 - acc: 0.8794 - val_loss: 1.1586 - val_acc: 0.6950\n",
      "Epoch 466/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5586 - acc: 0.8924 - val_loss: 1.1456 - val_acc: 0.7151\n",
      "Epoch 467/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5678 - acc: 0.8848 - val_loss: 1.1319 - val_acc: 0.7222\n",
      "Epoch 468/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5803 - acc: 0.8845 - val_loss: 1.1943 - val_acc: 0.7116\n",
      "Epoch 469/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5448 - acc: 0.8986 - val_loss: 1.1966 - val_acc: 0.7021\n",
      "Epoch 470/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5643 - acc: 0.8910 - val_loss: 1.3320 - val_acc: 0.6986\n",
      "Epoch 471/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5689 - acc: 0.8865 - val_loss: 1.2657 - val_acc: 0.6868\n",
      "Epoch 472/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5733 - acc: 0.8821 - val_loss: 1.2234 - val_acc: 0.6785\n",
      "Epoch 473/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5764 - acc: 0.8797 - val_loss: 1.2682 - val_acc: 0.6950\n",
      "Epoch 474/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5631 - acc: 0.8907 - val_loss: 1.2285 - val_acc: 0.6891\n",
      "Epoch 475/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5708 - acc: 0.8892 - val_loss: 1.2021 - val_acc: 0.6903\n",
      "Epoch 476/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5644 - acc: 0.8904 - val_loss: 1.1230 - val_acc: 0.7199\n",
      "Epoch 477/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5549 - acc: 0.8945 - val_loss: 1.1179 - val_acc: 0.7151\n",
      "Epoch 478/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5757 - acc: 0.8877 - val_loss: 1.1567 - val_acc: 0.7092\n",
      "Epoch 479/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5354 - acc: 0.8963 - val_loss: 1.0973 - val_acc: 0.7423\n",
      "Epoch 480/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5378 - acc: 0.9004 - val_loss: 1.1965 - val_acc: 0.7104\n",
      "Epoch 481/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5412 - acc: 0.9040 - val_loss: 1.1500 - val_acc: 0.7033\n",
      "Epoch 482/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5529 - acc: 0.8939 - val_loss: 1.2374 - val_acc: 0.6915\n",
      "Epoch 483/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5475 - acc: 0.8983 - val_loss: 1.1593 - val_acc: 0.7092\n",
      "Epoch 484/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5455 - acc: 0.8989 - val_loss: 1.2146 - val_acc: 0.6927\n",
      "Epoch 485/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5822 - acc: 0.8848 - val_loss: 1.1586 - val_acc: 0.7163\n",
      "Epoch 486/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5494 - acc: 0.8945 - val_loss: 1.1187 - val_acc: 0.7258\n",
      "Epoch 487/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5586 - acc: 0.8874 - val_loss: 1.2734 - val_acc: 0.6879\n",
      "Epoch 488/500\n",
      "3384/3384 [==============================] - 1s 416us/step - loss: 0.5708 - acc: 0.8812 - val_loss: 1.2178 - val_acc: 0.6986\n",
      "Epoch 489/500\n",
      "3384/3384 [==============================] - 1s 417us/step - loss: 0.5746 - acc: 0.8883 - val_loss: 1.1563 - val_acc: 0.7104\n",
      "Epoch 490/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5872 - acc: 0.8774 - val_loss: 1.0936 - val_acc: 0.7376\n",
      "Epoch 491/500\n",
      "3384/3384 [==============================] - 1s 420us/step - loss: 0.5476 - acc: 0.8986 - val_loss: 1.1214 - val_acc: 0.7246\n",
      "Epoch 492/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5479 - acc: 0.8978 - val_loss: 1.2661 - val_acc: 0.6962\n",
      "Epoch 493/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5718 - acc: 0.8862 - val_loss: 1.2334 - val_acc: 0.6950\n",
      "Epoch 494/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5444 - acc: 0.8998 - val_loss: 1.1022 - val_acc: 0.7258\n",
      "Epoch 495/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5341 - acc: 0.9040 - val_loss: 1.1954 - val_acc: 0.7163\n",
      "Epoch 496/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5567 - acc: 0.8856 - val_loss: 1.1311 - val_acc: 0.7234\n",
      "Epoch 497/500\n",
      "3384/3384 [==============================] - 1s 419us/step - loss: 0.5576 - acc: 0.8915 - val_loss: 1.1727 - val_acc: 0.7045\n",
      "Epoch 498/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5610 - acc: 0.8910 - val_loss: 1.2524 - val_acc: 0.6891\n",
      "Epoch 499/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5576 - acc: 0.8951 - val_loss: 1.1525 - val_acc: 0.7234\n",
      "Epoch 500/500\n",
      "3384/3384 [==============================] - 1s 418us/step - loss: 0.5535 - acc: 0.8957 - val_loss: 1.1329 - val_acc: 0.7163\n",
      "886/886 [==============================] - 0s 213us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0375393637146961, 0.7336343113778676]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "with tf.Session( config = tf.ConfigProto( log_device_placement = True ) ):\n",
    "    #model.fit(new_train,yy_train,validation_data=(new_valid,yy_valid),epochs=500,batch_size=60,shuffle=True,callbacks=[early_stopping])\n",
    "    history=model.fit(new_train,yy_train,validation_data=(new_valid,yy_valid),epochs=500,batch_size=60,shuffle=True)\n",
    "    model.evaluate(x=new_test, y=yy_test_onehot)\n",
    "    score=model.predict(x=new_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy is: 0.7268623024830699\n"
     ]
    }
   ],
   "source": [
    "y_score=np.zeros([y_test.shape[0],4],dtype='float64')\n",
    "for i in range(n_sub)  :\n",
    "    y_score+=np.log(score[i*n_test:(i+1)*n_test])\n",
    "y_pred=np.argmax(y_score,axis=1)\n",
    "print ('Testing data accuracy is: {}'.format(sum(y_pred==y_test)/y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25646c4b320>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25646b6b828>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'model accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25646c4b860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x256463b6940>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25646c4bb00>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'model loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x256463b6e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8ded627de5d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m plot_confusion_matrix(y_test, y_pred, classes=class_names,\n\u001b[0m\u001b[0;32m     55\u001b[0m                       title='Confusion matrix, without normalization')\n\u001b[0;32m     56\u001b[0m plot_confusion_matrix(y_test, y_pred, classes=class_names,normalize=True,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "class_names = np.array(['left','right','foot','tongue'])\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true,y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "   # else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names,normalize=True,\n",
    "                      title='Confusion matrix, with normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNN++</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subject_0</th>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_1</th>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_2</th>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_3</th>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_4</th>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_5</th>\n",
       "      <td>0.632653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_6</th>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_7</th>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_8</th>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CNN++\n",
       "Subject_0  0.680000\n",
       "Subject_1  0.660000\n",
       "Subject_2  0.780000\n",
       "Subject_3  0.640000\n",
       "Subject_4  0.808511\n",
       "Subject_5  0.632653\n",
       "Subject_6  0.860000\n",
       "Subject_7  0.820000\n",
       "Subject_8  0.787234"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.zeros([9,1])\n",
    "for i in range(9):\n",
    "        data[i]=sum(y_pred[test_subject_idx[i]]==y_test[test_subject_idx[i]])/len(test_subject_idx[i])\n",
    "\n",
    "column_name=['CNN++']\n",
    "idx_name=['Subject_0', 'Subject_1','Subject_2','Subject_3','Subject_4','Subject_5','Subject_6','Subject_7','Subject_8']\n",
    "df = pd.DataFrame(data=data,index=idx_name, columns=column_name)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
